{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1755 images belonging to 7 classes.\n",
      "Found 181 images belonging to 7 classes.\n",
      "Found 64 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "trainbatches = ImageDataGenerator(rescale= 1./255).flow_from_directory('imgs/train',\\\n",
    "                                                                       target_size=(100,200), \\\n",
    "                                                                       #classes=['0','1','-1','2','-2','3','-3'],\\\n",
    "                                                                      batch_size=50)\n",
    "validatebatches = ImageDataGenerator(rescale= 1./255).flow_from_directory('imgs/validate',\\\n",
    "                                                                       target_size=(100,200), \\\n",
    "                                                                       #classes=['0','1','-1','2','-2','3','-3'],\\\n",
    "                                                                      batch_size=45)\n",
    "testbatches = ImageDataGenerator(rescale = 1./255).flow_from_directory('imgs/test',\\\n",
    "                                                                      target_size=(100,200),\\\n",
    "                                                                      #classes=['0','1','-1','2','-2','3','-3'],\\\n",
    "                                                                      batch_size=64);\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000,28,28,1)\n",
    "X_test = X_test.reshape(10000,28,28,1)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "classifier = Sequential();\n",
    "classifier.add(Conv2D(64,(3,3),activation = 'relu', input_shape = (100,200,3)))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Conv2D(32,(3,3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Conv2D(28,(3,3),activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(7,activation = 'softmax'))\n",
    "#sgd = SGD(lr = 0.001,momentum = 0.9)\n",
    "classifier.compile(optimizer='adam', loss = 'categorical_crossentropy' ,metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/103\n",
      "32/32 [==============================] - 36s 1s/step - loss: 1.8573 - acc: 0.2369 - val_loss: 1.8968 - val_acc: 0.2667\n",
      "Epoch 2/103\n",
      "32/32 [==============================] - 33s 1s/step - loss: 1.7321 - acc: 0.2809 - val_loss: 1.7548 - val_acc: 0.3676\n",
      "Epoch 3/103\n",
      "32/32 [==============================] - 34s 1s/step - loss: 1.6469 - acc: 0.3197 - val_loss: 1.6329 - val_acc: 0.4265\n",
      "Epoch 4/103\n",
      "32/32 [==============================] - 34s 1s/step - loss: 1.5815 - acc: 0.3464 - val_loss: 1.7256 - val_acc: 0.2941\n",
      "Epoch 5/103\n",
      "32/32 [==============================] - 33s 1s/step - loss: 1.5462 - acc: 0.3744 - val_loss: 1.6557 - val_acc: 0.3088\n",
      "Epoch 6/103\n",
      "32/32 [==============================] - 37s 1s/step - loss: 1.3849 - acc: 0.4120 - val_loss: 1.4300 - val_acc: 0.4111\n",
      "Epoch 7/103\n",
      "32/32 [==============================] - 36s 1s/step - loss: 1.3411 - acc: 0.4396 - val_loss: 1.4220 - val_acc: 0.4926\n",
      "Epoch 8/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 1.2138 - acc: 0.4811 - val_loss: 1.3952 - val_acc: 0.3897\n",
      "Epoch 9/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 1.2000 - acc: 0.4815 - val_loss: 1.3371 - val_acc: 0.5294\n",
      "Epoch 10/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 1.1444 - acc: 0.5100 - val_loss: 1.3146 - val_acc: 0.4265\n",
      "Epoch 11/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 1.0645 - acc: 0.5660 - val_loss: 1.3026 - val_acc: 0.5000\n",
      "Epoch 12/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 1.0483 - acc: 0.5646 - val_loss: 1.2371 - val_acc: 0.5515\n",
      "Epoch 13/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 1.0409 - acc: 0.5606 - val_loss: 1.2693 - val_acc: 0.4706\n",
      "Epoch 14/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 1.2965 - acc: 0.5053 - val_loss: 1.6657 - val_acc: 0.3897\n",
      "Epoch 15/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 1.1450 - acc: 0.5072 - val_loss: 1.2288 - val_acc: 0.5441\n",
      "Epoch 16/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 1.0613 - acc: 0.5679 - val_loss: 1.1723 - val_acc: 0.5222\n",
      "Epoch 17/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.9358 - acc: 0.6055 - val_loss: 1.1841 - val_acc: 0.5368\n",
      "Epoch 18/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.9239 - acc: 0.6152 - val_loss: 1.1329 - val_acc: 0.6250\n",
      "Epoch 19/103\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.9049 - acc: 0.6188 - val_loss: 1.0543 - val_acc: 0.5735\n",
      "Epoch 20/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.9270 - acc: 0.6044 - val_loss: 1.0882 - val_acc: 0.6176\n",
      "Epoch 21/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.9455 - acc: 0.6119 - val_loss: 1.1623 - val_acc: 0.5556\n",
      "Epoch 22/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 1.0429 - acc: 0.5754 - val_loss: 1.0907 - val_acc: 0.6544\n",
      "Epoch 23/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.8797 - acc: 0.6213 - val_loss: 0.9845 - val_acc: 0.6471\n",
      "Epoch 24/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.8719 - acc: 0.6477 - val_loss: 1.1073 - val_acc: 0.5221\n",
      "Epoch 25/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.8089 - acc: 0.6444 - val_loss: 0.9935 - val_acc: 0.5735\n",
      "Epoch 26/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.8307 - acc: 0.6624 - val_loss: 1.0068 - val_acc: 0.6056\n",
      "Epoch 27/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.8677 - acc: 0.6402 - val_loss: 0.9996 - val_acc: 0.6765\n",
      "Epoch 28/103\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.8461 - acc: 0.6369 - val_loss: 0.9143 - val_acc: 0.6765\n",
      "Epoch 29/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.8934 - acc: 0.6241 - val_loss: 0.9733 - val_acc: 0.7279\n",
      "Epoch 30/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.7447 - acc: 0.6926 - val_loss: 0.9245 - val_acc: 0.6985\n",
      "Epoch 31/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.7922 - acc: 0.6976 - val_loss: 0.9554 - val_acc: 0.6944\n",
      "Epoch 32/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.7777 - acc: 0.6757 - val_loss: 0.8862 - val_acc: 0.6471\n",
      "Epoch 33/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.7379 - acc: 0.7088 - val_loss: 0.9187 - val_acc: 0.6618\n",
      "Epoch 34/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.7078 - acc: 0.7051 - val_loss: 0.8280 - val_acc: 0.7426\n",
      "Epoch 35/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.7299 - acc: 0.7018 - val_loss: 1.0526 - val_acc: 0.6324\n",
      "Epoch 36/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.7694 - acc: 0.6967 - val_loss: 0.9549 - val_acc: 0.6500\n",
      "Epoch 37/103\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.9170 - acc: 0.6306 - val_loss: 0.8646 - val_acc: 0.6544\n",
      "Epoch 38/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.6661 - acc: 0.7387 - val_loss: 0.8282 - val_acc: 0.6397\n",
      "Epoch 39/103\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.7265 - acc: 0.6961 - val_loss: 0.9087 - val_acc: 0.6618\n",
      "Epoch 40/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.6238 - acc: 0.7543 - val_loss: 0.7756 - val_acc: 0.7279\n",
      "Epoch 41/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.6044 - acc: 0.7811 - val_loss: 0.8523 - val_acc: 0.6556\n",
      "Epoch 42/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.7475 - acc: 0.7240 - val_loss: 0.8399 - val_acc: 0.6324\n",
      "Epoch 43/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.7031 - acc: 0.7084 - val_loss: 0.8402 - val_acc: 0.7059\n",
      "Epoch 44/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.6099 - acc: 0.7598 - val_loss: 0.7413 - val_acc: 0.7353\n",
      "Epoch 45/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.6080 - acc: 0.7595 - val_loss: 0.6692 - val_acc: 0.7941\n",
      "Epoch 46/103\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.5418 - acc: 0.8012 - val_loss: 0.6351 - val_acc: 0.8056\n",
      "Epoch 47/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.6063 - acc: 0.7710 - val_loss: 0.6959 - val_acc: 0.7868\n",
      "Epoch 48/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.5701 - acc: 0.7716 - val_loss: 0.6344 - val_acc: 0.7500\n",
      "Epoch 49/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.5249 - acc: 0.7961 - val_loss: 0.8408 - val_acc: 0.6324\n",
      "Epoch 50/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.6048 - acc: 0.7601 - val_loss: 0.7265 - val_acc: 0.7353\n",
      "Epoch 51/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.5404 - acc: 0.7831 - val_loss: 0.6509 - val_acc: 0.7889\n",
      "Epoch 52/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.5532 - acc: 0.7794 - val_loss: 0.7014 - val_acc: 0.7500\n",
      "Epoch 53/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.5245 - acc: 0.8217 - val_loss: 0.6083 - val_acc: 0.7868\n",
      "Epoch 54/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.4725 - acc: 0.8180 - val_loss: 0.7715 - val_acc: 0.7059\n",
      "Epoch 55/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.5458 - acc: 0.7900 - val_loss: 0.5732 - val_acc: 0.8162\n",
      "Epoch 56/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.6061 - acc: 0.7564 - val_loss: 0.5778 - val_acc: 0.8167\n",
      "Epoch 57/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.4935 - acc: 0.8106 - val_loss: 0.7704 - val_acc: 0.6765\n",
      "Epoch 58/103\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.4813 - acc: 0.8155 - val_loss: 0.5881 - val_acc: 0.7574\n",
      "Epoch 59/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.5275 - acc: 0.7883 - val_loss: 0.6983 - val_acc: 0.7353\n",
      "Epoch 60/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.5104 - acc: 0.8025 - val_loss: 0.7380 - val_acc: 0.7206\n",
      "Epoch 61/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.4658 - acc: 0.8299 - val_loss: 0.5356 - val_acc: 0.8278\n",
      "Epoch 62/103\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.4097 - acc: 0.8480 - val_loss: 0.5721 - val_acc: 0.7868\n",
      "Epoch 63/103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 35s 1s/step - loss: 0.4128 - acc: 0.8480 - val_loss: 0.8395 - val_acc: 0.6544\n",
      "Epoch 64/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.4384 - acc: 0.8225 - val_loss: 0.5296 - val_acc: 0.8015\n",
      "Epoch 65/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.4225 - acc: 0.8342 - val_loss: 0.4472 - val_acc: 0.8824\n",
      "Epoch 66/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.4601 - acc: 0.8280 - val_loss: 0.6615 - val_acc: 0.7389\n",
      "Epoch 67/103\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.4482 - acc: 0.8325 - val_loss: 0.4993 - val_acc: 0.8309\n",
      "Epoch 68/103\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.4716 - acc: 0.8233 - val_loss: 0.5969 - val_acc: 0.7647\n",
      "Epoch 69/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.4711 - acc: 0.8194 - val_loss: 0.7136 - val_acc: 0.7059\n",
      "Epoch 70/103\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.4015 - acc: 0.8425 - val_loss: 0.5486 - val_acc: 0.7794\n",
      "Epoch 71/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.3777 - acc: 0.8576 - val_loss: 0.4526 - val_acc: 0.8278\n",
      "Epoch 72/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.4340 - acc: 0.8248 - val_loss: 0.5239 - val_acc: 0.8235\n",
      "Epoch 73/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.3822 - acc: 0.8544 - val_loss: 0.4297 - val_acc: 0.8897\n",
      "Epoch 74/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.3933 - acc: 0.8619 - val_loss: 0.5313 - val_acc: 0.7941\n",
      "Epoch 75/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.3657 - acc: 0.8640 - val_loss: 0.3995 - val_acc: 0.8897\n",
      "Epoch 76/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.3694 - acc: 0.8524 - val_loss: 0.4266 - val_acc: 0.8667\n",
      "Epoch 77/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.3462 - acc: 0.8769 - val_loss: 0.5961 - val_acc: 0.7574\n",
      "Epoch 78/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.3538 - acc: 0.8593 - val_loss: 0.4222 - val_acc: 0.8603\n",
      "Epoch 79/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.3300 - acc: 0.8830 - val_loss: 0.3414 - val_acc: 0.8824\n",
      "Epoch 80/103\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.3590 - acc: 0.8738 - val_loss: 0.5966 - val_acc: 0.6838\n",
      "Epoch 81/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.3446 - acc: 0.8652 - val_loss: 0.4353 - val_acc: 0.8222\n",
      "Epoch 82/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.3495 - acc: 0.8687 - val_loss: 0.3903 - val_acc: 0.8603\n",
      "Epoch 83/103\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.2863 - acc: 0.9018 - val_loss: 0.4555 - val_acc: 0.8382\n",
      "Epoch 84/103\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.4112 - acc: 0.8469 - val_loss: 0.5640 - val_acc: 0.8015\n",
      "Epoch 85/103\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.3029 - acc: 0.8818 - val_loss: 0.3224 - val_acc: 0.9191\n",
      "Epoch 86/103\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.2983 - acc: 0.8813 - val_loss: 0.3326 - val_acc: 0.8889\n",
      "Epoch 87/103\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.3035 - acc: 0.8749 - val_loss: 0.3526 - val_acc: 0.9191\n",
      "Epoch 88/103\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.2607 - acc: 0.9124 - val_loss: 0.3809 - val_acc: 0.8750\n",
      "Epoch 89/103\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.2641 - acc: 0.8957 - val_loss: 0.4691 - val_acc: 0.8309\n",
      "Epoch 90/103\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.3607 - acc: 0.8634 - val_loss: 0.3334 - val_acc: 0.8824\n",
      "Epoch 91/103\n",
      "32/32 [==============================] - 35s 1s/step - loss: 0.3964 - acc: 0.8519 - val_loss: 0.4452 - val_acc: 0.8500\n",
      "Epoch 92/103\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.3877 - acc: 0.8490 - val_loss: 0.3360 - val_acc: 0.8897\n",
      "Epoch 93/103\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.3793 - acc: 0.8507 - val_loss: 0.4129 - val_acc: 0.8235\n",
      "Epoch 94/103\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.3193 - acc: 0.8769 - val_loss: 0.2945 - val_acc: 0.9265\n",
      "Epoch 95/103\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.3083 - acc: 0.8751 - val_loss: 0.5335 - val_acc: 0.7794\n",
      "Epoch 96/103\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.2919 - acc: 0.8930 - val_loss: 0.3208 - val_acc: 0.9222\n",
      "Epoch 97/103\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.2658 - acc: 0.8974 - val_loss: 0.4410 - val_acc: 0.8382\n",
      "Epoch 98/103\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.3386 - acc: 0.8779 - val_loss: 1.1068 - val_acc: 0.6176\n",
      "Epoch 99/103\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.4028 - acc: 0.8563 - val_loss: 0.5115 - val_acc: 0.8309\n",
      "Epoch 100/103\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.3017 - acc: 0.8806 - val_loss: 0.3478 - val_acc: 0.8971\n",
      "Epoch 101/103\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.4544 - acc: 0.8413 - val_loss: 0.4815 - val_acc: 0.8056\n",
      "Epoch 102/103\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.2878 - acc: 0.8937 - val_loss: 0.3032 - val_acc: 0.9044\n",
      "Epoch 103/103\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.2440 - acc: 0.9130 - val_loss: 0.3259 - val_acc: 0.8897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d38a7c9cc0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(trainbatches, steps_per_epoch = 32, validation_data = validatebatches, validation_steps = 4, epochs = 103)\n",
    "#classifier.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_77 (Conv2D)           (None, 98, 198, 64)       1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 49, 99, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 49, 99, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 47, 97, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 23, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 23, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 21, 46, 28)        8092      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 10, 23, 28)        0         \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 10, 23, 28)        0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 6440)              0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 7)                 45087     \n",
      "=================================================================\n",
      "Total params: 73,435\n",
      "Trainable params: 73,435\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving Model\n",
    "classifier_json = classifier.to_json();\n",
    "with open(\"classifier2.json\",\"w\") as json_file:\n",
    "    json_file.write(classifier_json)\n",
    "classifier.save_weights(\"classifier2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "testbatches = ImageDataGenerator(rescale = 1./255).flow_from_directory('faulty/test',\\\n",
    "                                                                      target_size=(100,200),\\\n",
    "                                                                      #classes=['0','1','-1','2','-2','3','-3'],\\\n",
    "                                                                      batch_size=162);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 200, 3)\n",
      "[[0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "\n",
      "\n",
      "[[0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "testimgs,testlabels = next(testbatches);\n",
    "print(np.shape(testimgs))\n",
    "print(testlabels)\n",
    "print('\\n\\n')\n",
    "#prediction = classifier.predict_generator(testbatches,steps=1)\n",
    "prediction = classifier.predict(testimgs)\n",
    "print(prediction.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = 0\n",
    "row = []\n",
    "confusion_matrix = np.zeros((7,8));\n",
    "for i in range(prediction.shape[0]):\n",
    "    if (np.array_equal((prediction[i,:]).round(),testlabels[i,:])):\n",
    "        test_acc += 1\n",
    "        which_rate = 0\n",
    "        for j in range(prediction.shape[1]):\n",
    "            if(testlabels[i,j] == 1):\n",
    "                which_rate = j\n",
    "        confusion_matrix[which_rate,which_rate] += 1;\n",
    "    else:\n",
    "        row.append(i)\n",
    "        which_rate_right = 0\n",
    "        which_rate_wrong2 = 7\n",
    "        for j in range(prediction.shape[1]):\n",
    "            if((prediction[i,j]).round() == 1):\n",
    "                which_rate_wrong2 = j;\n",
    "        for j in range(prediction.shape[1]):\n",
    "            if(testlabels[i,j] == 1):\n",
    "                which_rate_right = j;\n",
    "        confusion_matrix[which_rate_right, which_rate_wrong2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63\n",
      "[0, 1, 2, 4, 7, 12, 13, 14, 15, 17, 18, 21, 22, 24, 27, 32, 38, 40, 44, 46, 51, 55, 57, 58, 61, 62, 66, 76, 78, 79, 83, 85, 87, 90, 92, 94, 98]\n",
      "[[11.  1.  1.  6.  0.  0.  0.  1.]\n",
      " [ 3.  6.  0.  0.  0.  0.  0.  1.]\n",
      " [ 2.  0.  5.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0. 21.  4.  0.  0.  0.]\n",
      " [ 0.  0.  0.  6. 11.  0.  2.  1.]\n",
      " [ 0.  0.  0.  0.  3.  2.  5.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  7.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(test_acc / prediction.shape[0])\n",
    "print(row)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('which one failed',np.uint8(testimgs[57,:,:,:]*255));\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in row:\n",
    "    im = Image.fromarray(np.uint8(testimgs[i,:,:,:]*255));\n",
    "    im.save(pathlib.Path.cwd()/'classifier2_failed_imgs'/('Outdoor_' + str(i) + '.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print((prediction.round())[85])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print((testlabels[85]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
